epoch,training_loss
1,1.9129968897898992
2,1.9128340615828832
3,1.912834059516589
4,1.9128340582052867
5,1.9128340617815653
6,1.9128340607484182
7,1.9128340576092402
8,1.9128340569734574
9,1.9128340607484182
10,1.9128340604702632
11,1.9128340583642325
12,1.9128340605894725
13,1.9128340580066046
14,1.9128340604305267
15,1.9128340611457824
16,1.9128340593576432
17,1.9128340609868368
18,1.9128340592384339
19,1.9128340633710226
20,1.9128340602318445
21,1.9128340595960618
22,1.9128340593973796
23,1.9128340603510539
24,1.9128340632120768
25,1.9128340616226196
26,1.9128340593179067
27,1.9128340626955032
28,1.9128340581655503
29,1.912834059516589
30,1.9128340625762938
31,1.9128340597947437
32,1.9128340598344802
33,1.912834059516589
34,1.912834058046341
35,1.9128340611855188
36,1.9128340607086818
37,1.912834059715271
38,1.9128340616226196
39,1.9128340622186661
40,1.9128340589205424
41,1.9128340617020925
42,1.9128340598742166
43,1.912834058324496
44,1.9128340590397517
45,1.9128340590397517
46,1.9128340601126352
47,1.9128340603113174
48,1.912834059993426
49,1.9128340612252552
50,1.9128340597947437
