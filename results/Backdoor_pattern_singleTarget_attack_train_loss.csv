epoch,training_loss
1,1.913521851936976
2,1.913234060327212
3,1.9132340610027314
4,1.9132340611219407
5,1.9132340610424678
6,1.9132340610822043
7,1.9132340602874756
8,1.913234058936437
9,1.9132340598901112
10,1.91323406068484
11,1.913234060327212
12,1.913234060049057
13,1.913234058856964
14,1.913234062075615
15,1.9132340586185455
16,1.9132340609232585
17,1.913234061161677
18,1.9132340591351191
19,1.913234060883522
20,1.9132340605656306
21,1.9132340600093205
22,1.91323406068484
23,1.913234060883522
24,1.91323405957222
25,1.9132340565522512
26,1.9132340615193049
27,1.9132340596119564
28,1.9132340592940649
29,1.913234059770902
30,1.9132340590953827
31,1.9132340577046076
32,1.9132340590953827
33,1.9132340610027314
34,1.9132340582609177
35,1.9132340606451035
36,1.913234060049057
37,1.9132340607643128
38,1.9132340570290884
39,1.9132340630690257
40,1.9132340581417084
41,1.9132340608040492
42,1.9132340593735377
43,1.913234059770902
44,1.9132340612808862
45,1.9132340599298476
46,1.9132340590159098
47,1.9132340598503748
48,1.9132340582211813
49,1.9132340596119564
50,1.9132340608040492
