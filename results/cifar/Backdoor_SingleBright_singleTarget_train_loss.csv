epoch,training_loss
1,1.913907578686619
2,1.911618455596592
3,1.9113786604703236
4,1.9113786568117264
5,1.911138886838313
6,1.9110190000985285
7,1.911078939657382
8,1.9113786525433631
9,1.9112587661084617
10,1.9116184232789841
11,1.9112587668706693
12,1.9111988280740235
13,1.9115584821957152
14,1.9113786552873109
15,1.911318711155211
16,1.9112587679377602
17,1.9114385942363983
18,1.9112587677853188
19,1.9114985377587321
20,1.9113786517811553
21,1.9113786525433631
22,1.9114584534064583
23,1.911198826244725
24,1.9113187106978862
25,1.9114985386733814
26,1.9113187105454448
27,1.9113786528482462
28,1.911438594693723
29,1.9113187093259123
30,1.9110189984216714
31,1.9114985363867583
32,1.9113786531531292
33,1.911378650866506
34,1.9112587683950848
35,1.9113786531531292
36,1.9114385978949955
37,1.9113187113076524
38,1.9112587674804355
39,1.911318709173471
40,1.911438593016866
41,1.9114385937790737
42,1.9114985365391997
43,1.9112587683950848
44,1.9111988291411144
45,1.9113786523909215
46,1.9113786526958045
47,1.9111988233483357
48,1.9113187085637047
49,1.9114385942363983
50,1.9112587653462538
