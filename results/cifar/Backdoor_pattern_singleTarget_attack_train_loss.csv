epoch,training_loss
1,1.9105394587797278
2,1.9107792269238426
3,1.9105994007776461
4,1.910839171513267
5,1.9110189997936453
6,1.9108391690742024
7,1.9107792289055827
8,1.9108391701412932
9,1.9104795164769264
10,1.9109590573384023
11,1.910839169226644
12,1.9108391731901242
13,1.9107192855356905
14,1.910719284011275
15,1.9109590570335193
16,1.9110189993363207
17,1.9108391716657087
18,1.9107192866027813
19,1.9107192853832489
20,1.9107792272287256
21,1.9108991130538608
22,1.9108991129014192
23,1.9107792281433749
24,1.9107792282958165
25,1.9108991127489778
26,1.910839168921761
27,1.9105394584748445
28,1.9110189959826067
29,1.9106593430804475
30,1.9108391710559425
31,1.9107192827917425
32,1.9107792292104657
33,1.9109590539846883
34,1.9105994001678799
35,1.9108391713608257
36,1.9106593442999797
37,1.9107792269238426
38,1.9107192847734826
39,1.910839169226644
40,1.9107792281433749
41,1.9107792272287256
42,1.9105993995581136
43,1.9108391684644364
44,1.9108391713608257
45,1.9108391718181503
46,1.9107192841637166
47,1.910719285993015
48,1.9107192853832489
49,1.9105994016922954
50,1.9107192869076643
