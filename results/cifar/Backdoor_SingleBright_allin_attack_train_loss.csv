epoch,training_loss
1,1.9116384024205415
2,1.9116983474672908
3,1.9118781745281366
4,1.9117582915993907
5,1.9115784620994802
6,1.911818230548478
7,1.9118781734610457
8,1.9115784607275064
9,1.9116384016583339
10,1.9117582870261443
11,1.9116384031827494
12,1.9116384027254245
13,1.9117582873310275
14,1.9118182294813872
15,1.9116983470099662
16,1.9118781734610457
17,1.9116983471624076
18,1.9115185199491203
19,1.9116384044022816
20,1.911758289160326
21,1.9116384031827494
22,1.9117582868737029
23,1.9117582885505597
24,1.9117582912945077
25,1.911818231310686
26,1.911698346705083
27,1.9117582893127676
28,1.9117582880932351
29,1.9115185161380817
30,1.9115185184247048
31,1.9116384045547232
32,1.9117582879407937
33,1.9116384047071646
34,1.912058001741424
35,1.9117582903798584
36,1.9118182307009197
37,1.9121179449588745
38,1.9116384037925154
39,1.9116384034876324
40,1.911818231615569
41,1.9119980580666487
42,1.911878173003721
43,1.9118182307009197
44,1.911758287483469
45,1.9116983451806675
46,1.9118182317680106
47,1.9117582880932351
48,1.9116983454855507
49,1.9115784610323894
50,1.9116384031827494
