epoch,training_loss
1,1.5407010593811672
2,1.4907882956663767
3,1.4846951880057653
4,1.4793224084774652
5,1.4782829912900926
6,1.47706885433197
7,1.475008399049441
8,1.4748993440469107
9,1.4745187134345372
10,1.4739747538169226
11,1.4735095564921696
12,1.4744200884103775
13,1.4722312947511673
14,1.473279179930687
15,1.4721295323769252
16,1.472185734629631
17,1.4721547124783199
18,1.4721195802688598
19,1.472778888265292
20,1.4720531891584396
21,1.4709976977109909
22,1.4716621354818344
23,1.4711947305599848
24,1.4706932680606841
25,1.4700860565503437
26,1.4716345780690512
27,1.4714058646758397
28,1.471378699183464
29,1.4710769418875376
30,1.4699961897532146
31,1.4725958221356075
32,1.4722152835528055
33,1.4701107151905695
34,1.4713818258841833
35,1.4723894848823547
36,1.4713799165884653
37,1.4709095863501231
38,1.4727976905107498
39,1.4702434917291005
40,1.4703587901592254
41,1.4706356033881505
42,1.4711711503267288
43,1.4753766411145528
44,1.4713836877743403
45,1.469943702697754
46,1.4720742843151093
47,1.47082437423865
48,1.4728095886309942
49,1.47200024497509
50,1.4697187074820202
